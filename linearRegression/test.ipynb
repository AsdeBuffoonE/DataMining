{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x = pd.read_csv('data/random_data_regression_X.csv', header=None)\n",
    "y = pd.read_csv('data/random_data_regression_y.csv', header=None)\n",
    "train_x = x[:40]\n",
    "train_y = y[:40]\n",
    "test_x = x[40:]\n",
    "test_y = y[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.25497844e-02, -1.00560511e-01,  1.04851350e-01,\n         4.86996715e-01,  5.20311779e-01, -1.44076826e-01,\n        -2.14945718e-01,  8.09543617e-01,  3.43146625e-01,\n        -3.91493771e-01,  1.79952155e-01,  3.17954774e-01,\n         3.45813643e-01,  1.28706628e-01,  4.04852268e-01,\n         2.82016541e-02, -4.82863226e-01,  1.35071623e-01,\n        -1.14934768e-01,  4.97576838e-01,  4.13551759e-01,\n         5.60225269e-01,  4.97820078e-01, -1.89745877e-01,\n        -4.76030964e-03, -1.05454275e-01,  4.20211356e-01,\n         1.86377282e-01, -3.80269519e-06,  9.55882235e-02,\n         2.68960660e-04,  2.96482635e-02,  7.56272966e-01,\n        -9.47270757e-02, -1.49262358e-01,  2.31451636e-01,\n         2.74836798e-01,  6.87454730e-01,  4.81759193e-01,\n         1.73444562e-02,  7.56190513e-02,  1.50697637e-01,\n         5.10692359e-01, -4.46807035e-01,  4.26574552e-01,\n         6.50658644e-01,  2.09098935e-01,  3.42808573e-01,\n         5.23128278e-01,  1.79306224e-01, -5.32121629e-02,\n         1.88544147e-01, -1.08598521e-01, -2.87061215e-01,\n         3.12276506e-01,  3.81395447e-01, -4.42722894e-01,\n        -1.09624585e-01,  8.58552913e-02,  6.67066300e-02,\n         2.82126887e-01,  1.39955577e-01, -6.79098747e-01,\n         9.60730067e-02,  3.18034441e-01, -9.41466776e-02,\n         4.36193789e-01,  2.07270466e-01, -3.39424661e-01,\n        -6.56350999e-02,  2.27139801e-01, -1.55386365e-01,\n         7.96596515e-02,  3.74388888e-02,  2.41611067e-01,\n        -3.19455231e-02,  1.26631621e-01,  6.96570136e-02,\n        -6.03987707e-01,  2.16198175e-01, -2.59628520e-01,\n         4.03545385e-01, -1.35054968e-01,  1.49879603e-01,\n        -5.88980320e-02, -3.97480605e-01, -6.71111288e-02,\n         2.95658199e-02,  4.59506250e-03, -7.89449473e-02,\n         5.97322236e-01,  2.30594111e-01,  1.62207331e-02,\n         6.03082733e-01, -2.62456285e-01,  4.63119775e-01,\n         2.82556184e-01, -1.78485200e-02,  2.60436801e-01,\n        -5.35140465e-02, -5.28158852e-03,  2.86283395e-01,\n        -3.52806709e-01, -3.11716205e-01, -1.33519154e-02,\n         1.69229081e-01,  2.76847005e-01,  1.28520847e-01,\n        -4.63687722e-01, -1.79277017e-01,  3.09662549e-01,\n        -4.31188896e-01,  5.05963874e-01, -2.78228342e-01,\n        -7.45091089e-02, -1.49352267e-01,  6.13960067e-01,\n         3.65914065e-01,  1.54019503e-01,  1.65758187e-01,\n        -3.41124276e-01, -1.44268347e-01, -1.66194429e-01,\n         9.91098378e-02,  1.58740604e-01, -4.81090481e-02,\n        -1.04284189e-01,  4.01041320e-01,  1.20006854e-02,\n        -3.14430068e-01, -7.82949811e-03, -4.73190894e-01,\n         3.12952368e-01,  8.22104813e-02, -1.57264355e-01,\n        -4.30833116e-01,  1.09080103e-01,  2.81048161e-01,\n        -6.36059981e-02, -1.55175010e-01,  2.19018944e-01,\n        -1.63676419e-02,  5.96599906e-01, -1.78151969e-01,\n         3.01785338e-01,  1.78644432e-01, -3.47013991e-01,\n         1.59671632e-01, -5.07412149e-01,  2.37644602e-01,\n         9.08530669e-02, -1.88709551e-02, -1.57262132e-01,\n         1.00331726e-01, -2.77475879e-01, -2.05220617e-01,\n        -1.82410491e-01,  3.09996632e-01, -3.35125491e-01,\n        -2.48237913e-01,  4.33289540e-01,  1.78536347e-01,\n         4.87537294e-02,  4.99263747e-01,  6.08131330e-01,\n        -6.31685206e-02, -3.97865457e-01,  2.73118403e-01,\n         9.65181197e-02, -5.04429595e-01, -3.13099855e-01,\n        -2.48622657e-01,  1.54111305e-01, -8.92557743e-01,\n        -7.72495652e-02, -4.05457406e-01, -1.11948653e-01,\n         3.13661832e-01, -3.13699113e-02, -8.62187598e-02,\n        -2.61641014e-01, -4.12337659e-02, -1.40068596e-01,\n        -2.34380205e-03, -3.57252489e-01, -3.71599562e-01,\n         1.29398345e-01,  4.61584876e-01,  1.35959527e-01,\n        -2.82739737e-02, -1.25973246e-01,  4.30888486e-01,\n         3.52699075e-01, -2.05111220e-01,  2.17319684e-01,\n         6.58834573e-02,  3.99016554e-01, -3.63296975e-01,\n        -5.96880723e-02, -4.01324755e-02, -2.04423065e-01,\n         6.58209035e-02,  2.67705962e-01,  7.42696700e-02,\n         4.73315423e-01, -3.83501529e-01,  1.03127303e-02,\n        -3.57213092e-01, -3.88736434e-01, -3.02925191e-01,\n         1.87538804e-01,  3.56686978e-02, -4.88522493e-03,\n        -1.21784234e-01, -1.95823277e-01,  1.98110248e-01,\n         5.21523386e-01, -4.28945673e-01,  3.65365394e-01,\n        -1.98506646e-01, -5.40465483e-02,  3.44053500e-03,\n         4.78056472e-02, -1.66805023e-01, -5.46802159e-01,\n        -1.23968740e-01, -3.78334642e-01, -3.83736394e-01,\n        -3.52691624e-01,  2.33265102e-03,  2.26400687e-01,\n        -1.09381397e-01,  1.49888073e-01,  1.45553456e-01,\n        -1.57359620e-01, -2.32753009e-01,  6.32872046e-01,\n        -2.82072857e-01, -4.55983833e-01, -4.24490292e-02,\n         1.51533645e-01, -3.51404195e-01, -3.60325109e-02,\n        -5.59575264e-01, -3.35461728e-01, -2.40178789e-02,\n         3.86903064e-01, -7.68321052e-02,  5.71544929e-01,\n         3.77889382e-01, -2.67618136e-01,  1.85727352e-01,\n         5.50998899e-01, -2.86880701e-02, -2.54733666e-01,\n         3.17917927e-01, -1.94161709e-01,  3.15744468e-02,\n        -2.45678914e-01, -7.70430097e-02,  3.76566365e-01,\n         9.14925805e-02, -8.39629474e-02,  1.41573772e-01,\n         1.46974533e-02,  5.30644596e-02,  2.64485533e-01,\n        -4.21892056e-01,  1.93209443e-02, -4.86488823e-01,\n         5.74043576e-02,  2.70800862e-01,  2.93722939e-02,\n        -2.83875022e-01,  4.78700715e-02,  7.58026745e-02,\n        -3.10560529e-01, -2.49950829e-01,  7.47431452e-04,\n        -1.02192681e-01, -2.98934891e-01, -5.11682404e-02,\n         2.17948673e-01,  3.14999745e-01, -1.73701969e-01,\n         1.55854203e-01,  3.75929991e-01,  1.48950495e-01,\n        -2.35685062e-01,  1.13075738e-01, -2.46705566e-01,\n        -5.23337761e-01, -1.64166702e-01,  1.47031029e-01,\n         3.58213433e-01, -1.53107882e-01,  4.45375793e-01,\n        -9.85605370e-02, -7.55467447e-01,  1.38887114e-01,\n        -2.27116551e-01,  1.86655614e-01,  3.45998569e-01,\n        -2.57128349e-01, -3.51348026e-01,  2.54731709e-01,\n        -2.16401586e-02, -7.40324644e-01,  3.83258692e-01,\n         1.73646560e-02, -3.28007601e-02, -1.29527623e-01,\n         3.85733705e-01, -9.68732058e-01,  2.66598898e-01,\n         1.47316148e-01, -4.34202236e-02, -2.10480976e-01,\n        -1.05893586e-01, -7.47164380e-02, -4.46404093e-01,\n         3.26049072e-01, -1.02017853e-02, -1.17312474e-01,\n         1.19564192e-02,  4.10821502e-01,  4.23600204e-02,\n        -1.46312996e-01,  4.07486037e-02, -2.24987765e-02,\n        -1.11793943e-01, -1.25381899e-01,  1.65430368e-01,\n         6.81810344e-01,  1.50818627e-01,  1.42859018e-01,\n         5.43291971e-02, -5.69332278e-02,  4.11415320e-01,\n        -4.75175132e-01, -8.85006501e-02, -8.69857139e-02,\n        -1.74160839e-01, -4.65660639e-02,  3.29935790e-01,\n        -6.37085636e-02,  1.32523295e-01,  8.54981426e-02,\n        -1.85901817e-01, -1.06492659e-01, -1.91635745e-01,\n         3.44656786e-01,  2.97928171e-01, -7.44975669e-02,\n         1.10555320e-01, -3.86192744e-02,  5.33164113e-02,\n         1.61185823e-01, -1.29544068e-01, -1.29543554e-01,\n        -7.35130498e-02,  8.16664224e-03,  3.13763596e-01,\n        -3.38487332e-02,  7.99069477e-02,  5.73773988e-02,\n        -5.50273819e-02,  2.48269289e-01,  5.71975079e-02,\n        -1.90949700e-01, -3.30210316e-01, -1.48184900e-01,\n        -9.40077796e-02,  2.70401803e-01,  1.73813759e-01,\n        -9.92253672e-02,  9.86868240e-02,  1.33301587e-02,\n        -1.46195466e-02,  8.51892215e-02,  2.17305932e-01,\n        -7.63351570e-02, -2.48608689e-01, -5.78428519e-01,\n         1.72205490e-01,  3.96697745e-01, -7.44660863e-02,\n        -2.69104507e-01,  2.28639386e-01,  7.72505687e-02,\n         4.29451740e-01,  3.23369094e-01, -2.15344388e-01,\n        -1.37845216e-01,  8.88192379e-02,  1.34971944e-03,\n        -5.01574855e-01,  8.74969445e-01,  7.79199535e-02,\n        -3.24679752e-01, -6.34024913e-01, -1.55028237e-02,\n         1.05860676e-01, -9.30365757e-02,  2.63567311e-01,\n        -1.39189569e-01,  3.16826309e-02,  1.28651664e-01,\n        -3.24797161e-01,  2.71583698e-01, -1.92654306e-01,\n        -2.61976041e-01,  2.82121724e-02,  6.07920264e-01,\n        -3.70375596e-01, -4.86566395e-01, -1.38782305e-01,\n        -3.46678686e-01,  4.86914622e-03,  2.17015938e-01,\n         3.92410485e-01,  9.10846250e-02,  1.00817718e-01,\n         6.10310901e-02, -4.86603531e-02, -3.58569115e-01,\n         3.96914291e-01,  5.73297846e-01, -6.79331419e-01,\n         1.17380609e-01, -8.65343012e-02,  5.60456438e-01,\n         8.67596932e-02,  1.34441763e-01,  2.10041285e-01,\n         3.16959581e-01, -7.00257712e-02,  1.23295590e-01,\n         5.09746115e-02,  3.71144463e-01, -1.13915635e-01,\n         2.91421729e-01, -3.26629617e-01, -1.89040127e-01,\n        -3.32051787e-01,  2.19322532e-02, -2.58438685e-01,\n         9.67609910e-02, -1.47626262e-01,  2.51002477e-01,\n         1.48694367e-01, -5.99397151e-01,  2.12659189e-01,\n         2.24423903e-01,  8.30854773e-02,  3.52156958e-01,\n         3.13107188e-01, -3.52331877e-01, -5.00663278e-01,\n        -4.00083299e-02, -4.69254185e-02, -3.59102121e-02,\n         2.02075180e-02, -1.89198440e-01, -4.86189010e-01,\n         2.64008658e-01,  5.85877749e-02, -6.08113306e-02,\n         3.56163795e-01, -2.86944275e-01,  5.55534985e-01,\n         9.95806563e-02,  2.34877759e-01,  1.50551624e-01,\n         2.17813794e-01, -2.16155285e-01, -3.28816970e-01,\n         1.50253437e-01,  2.54027336e-01,  2.93511554e-01,\n        -5.94463624e-02, -2.25712448e-01, -5.96924121e-02,\n        -1.18700987e-01, -6.20472319e-02, -3.30726973e-01,\n        -3.23076810e-03, -1.81743380e-01, -3.20689603e-01,\n         2.60952948e-01, -2.77408412e-01, -1.22830257e-01,\n        -2.19074125e-02,  6.09793163e-02,  2.43336362e-04,\n        -2.25379455e-01,  9.49177638e-02,  2.28924718e-02,\n        -1.34142217e-01,  2.01080937e-01]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(train_x, train_y)\n",
    "reg.coef_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "36.08490542501524"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pred = reg.predict(test_x)\n",
    "np.sqrt(mean_squared_error(test_y, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def GradientDescentLinerRegression(lr=0.01, max_iter=1000, early_stop=True, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    loss_arr = []\n",
    "    intercept_ = None\n",
    "    coef_ = None\n",
    "\n",
    "    x_b = np.hstack([np.ones((len(train_x), 1)), train_x])\n",
    "    x_b_dim = np.size(x_b, 1)\n",
    "    x_sample = np.size(x_b, 0)\n",
    "    w = np.random.normal(1, 0.001, (x_b_dim, 1))\n",
    "\n",
    "    def predict(x=None):\n",
    "        if x is None:\n",
    "            x = x_b\n",
    "        x = np.hstack([np.ones((len(x), 1)), x])\n",
    "        y_pred = x.dot(w)\n",
    "        return y_pred\n",
    "\n",
    "    def loss(is_test=True, y_true=None, y_pred=None):\n",
    "        if y_true is None or y_pred is None:\n",
    "            y_true = train_y\n",
    "        if is_test:\n",
    "            return np.sqrt(mean_squared_error(test_y, predict(test_x)))\n",
    "        else:\n",
    "            return np.sqrt(mean_squared_error(y_true, predict(train_x)))\n",
    "\n",
    "    for iter in range(max_iter):\n",
    "        d_w = np.empty(x_b_dim).reshape(-1, 1)\n",
    "        d_w[0] = np.sum(x_b.dot(w) - train_y)\n",
    "        for i in range(1, x_b_dim):\n",
    "            d_w[i] = np.squeeze((x_b.dot(w) - train_y)).dot(x_b[:, i].T)\n",
    "        d_w = d_w * 2 / x_sample\n",
    "        w = w - lr * d_w\n",
    "        intercept_ = w[0]\n",
    "        coef_ = w[1:]\n",
    "        loss_arr.append(loss())\n",
    "        print(\"iter: {}, loss_in_train: {:.5f}, loss_in_test: {:.5f}\".format(iter + 1, loss(is_test=False), loss_arr[-1]))\n",
    "\n",
    "        # 连续十次不下降则退出\n",
    "        if len(loss_arr) > 10:\n",
    "            arr = np.array(loss_arr[:-10])\n",
    "            if np.sum(arr[0] < arr) != 0:\n",
    "                return coef_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1, loss_in_train: 30.05101, loss_in_test: 35.13702\n",
      "iter: 2, loss_in_train: 29.30544, loss_in_test: 35.19389\n",
      "iter: 3, loss_in_train: 28.58021, loss_in_test: 35.25055\n",
      "iter: 4, loss_in_train: 27.87471, loss_in_test: 35.30694\n",
      "iter: 5, loss_in_train: 27.18835, loss_in_test: 35.36305\n",
      "iter: 6, loss_in_train: 26.52059, loss_in_test: 35.41883\n",
      "iter: 7, loss_in_train: 25.87086, loss_in_test: 35.47425\n",
      "iter: 8, loss_in_train: 25.23865, loss_in_test: 35.52929\n",
      "iter: 9, loss_in_train: 24.62343, loss_in_test: 35.58392\n",
      "iter: 10, loss_in_train: 24.02472, loss_in_test: 35.63813\n",
      "iter: 11, loss_in_train: 23.44202, loss_in_test: 35.69187\n",
      "iter: 12, loss_in_train: 22.87489, loss_in_test: 35.74515\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[1.09261969],\n       [0.79349094],\n       [0.95801036],\n       [1.06477521],\n       [1.05963035],\n       [0.95237846],\n       [0.99950903],\n       [1.14836516],\n       [1.03328593],\n       [0.93002229],\n       [1.01223663],\n       [0.99757775],\n       [1.16150878],\n       [0.97721074],\n       [1.26302989],\n       [0.98133402],\n       [0.94312599],\n       [1.04481292],\n       [1.08918588],\n       [1.04427823],\n       [1.22208703],\n       [1.2317482 ],\n       [1.09016045],\n       [0.92199862],\n       [0.91051162],\n       [0.94035439],\n       [1.10318628],\n       [1.03034938],\n       [1.00887389],\n       [0.93819239],\n       [0.93021149],\n       [1.07969397],\n       [1.03373772],\n       [1.01245775],\n       [1.01348906],\n       [1.02892913],\n       [1.08768104],\n       [1.16564234],\n       [1.11896794],\n       [0.97723755],\n       [0.87395948],\n       [0.98168584],\n       [1.0550796 ],\n       [0.89087366],\n       [1.03409349],\n       [1.26029931],\n       [1.07535919],\n       [1.06331862],\n       [1.12771922],\n       [1.10868036],\n       [1.0123259 ],\n       [1.03852141],\n       [1.00700214],\n       [1.10592259],\n       [1.08652828],\n       [1.000624  ],\n       [1.01749475],\n       [0.99436434],\n       [0.90552528],\n       [0.95340931],\n       [1.11445256],\n       [1.03068697],\n       [0.84649751],\n       [0.9324704 ],\n       [1.11898265],\n       [0.97626545],\n       [1.234886  ],\n       [0.98516329],\n       [0.89552393],\n       [0.89611083],\n       [0.88914885],\n       [0.95983603],\n       [0.93999406],\n       [1.03782714],\n       [1.01683093],\n       [1.07857844],\n       [0.93492499],\n       [0.95112707],\n       [0.95472304],\n       [1.07098483],\n       [0.96471823],\n       [1.01224277],\n       [0.98261239],\n       [0.93386436],\n       [0.9663311 ],\n       [0.90277064],\n       [0.92444549],\n       [0.91294446],\n       [0.92013422],\n       [1.01387331],\n       [0.97295699],\n       [1.02166804],\n       [0.96746014],\n       [1.01774309],\n       [0.90308945],\n       [1.06678018],\n       [1.00278655],\n       [1.00962536],\n       [0.92265913],\n       [0.69834828],\n       [0.89123194],\n       [0.99138566],\n       [0.79776735],\n       [0.87267039],\n       [0.98554121],\n       [1.06168574],\n       [1.03922048],\n       [0.84647969],\n       [0.91356824],\n       [0.80082669],\n       [0.98764501],\n       [0.77891406],\n       [1.06694588],\n       [0.86896922],\n       [1.02323533],\n       [0.87139059],\n       [1.10199634],\n       [0.95425954],\n       [0.9479577 ],\n       [1.05819164],\n       [0.8191699 ],\n       [0.73506099],\n       [0.84329657],\n       [0.97704873],\n       [0.93362578],\n       [0.95834535],\n       [0.92320714],\n       [1.18942093],\n       [1.0875478 ],\n       [0.89208974],\n       [0.98952794],\n       [0.79836022],\n       [1.19443981],\n       [1.0772969 ],\n       [1.01972809],\n       [0.78620002],\n       [1.14945768],\n       [1.06239863],\n       [0.78256423],\n       [0.81386575],\n       [0.88378614],\n       [0.94766123],\n       [1.15664567],\n       [0.88183374],\n       [0.84261987],\n       [1.07244177],\n       [0.83313145],\n       [0.911628  ],\n       [0.95413925],\n       [1.03752954],\n       [1.03548593],\n       [0.88257828],\n       [0.94513172],\n       [0.91276326],\n       [0.98169811],\n       [1.05603312],\n       [0.93588588],\n       [1.13609999],\n       [0.93625678],\n       [0.86613609],\n       [1.00182458],\n       [0.9818682 ],\n       [0.88886257],\n       [1.02555601],\n       [1.01553315],\n       [0.89428853],\n       [0.82867488],\n       [1.00427663],\n       [1.05777666],\n       [0.9703386 ],\n       [0.94238904],\n       [0.93969693],\n       [1.07072902],\n       [0.81674498],\n       [1.05435197],\n       [0.92784937],\n       [0.93401327],\n       [1.18591831],\n       [0.95486834],\n       [0.86995735],\n       [0.95273069],\n       [0.99798421],\n       [1.06932791],\n       [0.98796257],\n       [0.89811368],\n       [1.07013926],\n       [1.04248599],\n       [1.09493177],\n       [1.25874749],\n       [0.92619661],\n       [0.91243038],\n       [0.98213553],\n       [1.06274148],\n       [0.77719749],\n       [1.03944858],\n       [1.0083696 ],\n       [1.11818637],\n       [0.96222131],\n       [0.99443447],\n       [0.96583151],\n       [0.84029823],\n       [0.90067557],\n       [0.94499154],\n       [1.02156081],\n       [0.99334784],\n       [0.88221576],\n       [0.87397209],\n       [0.87125044],\n       [1.04158646],\n       [0.91253603],\n       [1.01930211],\n       [1.06711072],\n       [1.10316249],\n       [1.09341155],\n       [1.04377801],\n       [0.95185217],\n       [1.02068696],\n       [0.76635921],\n       [0.97166069],\n       [1.03242888],\n       [1.01984723],\n       [1.07442279],\n       [0.97462322],\n       [0.99738354],\n       [1.0292577 ],\n       [0.82276426],\n       [1.031316  ],\n       [1.05244664],\n       [0.88630679],\n       [0.88107389],\n       [1.04600364],\n       [0.8285674 ],\n       [1.00103514],\n       [0.99456204],\n       [0.92863081],\n       [0.88368516],\n       [0.99427463],\n       [0.96747984],\n       [0.86909448],\n       [0.94256786],\n       [1.0719331 ],\n       [0.91023567],\n       [1.08837562],\n       [0.83762878],\n       [0.8789561 ],\n       [1.09683228],\n       [0.91580901],\n       [0.892768  ],\n       [1.09933784],\n       [1.02428891],\n       [0.86189041],\n       [1.07478332],\n       [1.0360424 ],\n       [0.92827535],\n       [0.96486137],\n       [0.98971286],\n       [0.94599311],\n       [0.79925914],\n       [0.88318137],\n       [0.91453847],\n       [1.13508183],\n       [1.0359105 ],\n       [0.9551779 ],\n       [1.18245714],\n       [0.92136639],\n       [1.11063658],\n       [0.9734942 ],\n       [0.72678047],\n       [1.02282348],\n       [0.82620207],\n       [1.00229793],\n       [0.98400734],\n       [0.92963915],\n       [0.76941517],\n       [1.024219  ],\n       [1.00831754],\n       [0.91539126],\n       [0.96044549],\n       [1.02736112],\n       [0.93118177],\n       [0.87638839],\n       [0.90861653],\n       [0.88368626],\n       [0.90315135],\n       [0.90359503],\n       [0.90736621],\n       [0.85999574],\n       [0.9209516 ],\n       [1.01826514],\n       [0.85367876],\n       [1.03912285],\n       [0.83256507],\n       [0.91576101],\n       [0.99614872],\n       [1.03384589],\n       [1.01974351],\n       [1.10678309],\n       [1.06668412],\n       [0.67603935],\n       [1.12320283],\n       [1.03540335],\n       [0.98380889],\n       [1.02815657],\n       [0.91953002],\n       [0.8497036 ],\n       [1.02532887],\n       [0.95187552],\n       [0.83512461],\n       [0.96468163],\n       [1.03584664],\n       [0.98693862],\n       [0.93951976],\n       [1.05038609],\n       [0.92485985],\n       [1.09342076],\n       [0.84321743],\n       [0.87655738],\n       [0.9504989 ],\n       [0.89067163],\n       [1.02165008],\n       [0.92500551],\n       [1.0010428 ],\n       [1.01375495],\n       [0.85203303],\n       [1.01973027],\n       [1.06343287],\n       [1.02202831],\n       [0.88548139],\n       [1.02800514],\n       [0.87641074],\n       [0.81892425],\n       [1.03998131],\n       [1.00347631],\n       [1.26738061],\n       [0.93970164],\n       [0.96428418],\n       [1.06169515],\n       [0.96677367],\n       [1.0448214 ],\n       [0.96392268],\n       [0.91210622],\n       [0.95393079],\n       [0.81721281],\n       [1.01691609],\n       [1.09331839],\n       [0.97590606],\n       [0.9644266 ],\n       [1.12645786],\n       [0.8621075 ],\n       [0.86141782],\n       [0.98871615],\n       [0.97059748],\n       [1.02241796],\n       [0.99570095],\n       [0.89015261],\n       [0.88414294],\n       [0.89004509],\n       [0.92693017],\n       [0.93676158],\n       [1.03383993],\n       [0.94113411],\n       [0.91742831],\n       [1.02904621],\n       [0.83691685],\n       [1.09140637],\n       [0.96023236],\n       [0.92672394],\n       [1.03533718],\n       [1.02806271],\n       [0.94705277],\n       [0.84300009],\n       [0.97802044],\n       [0.86476264],\n       [0.97047421],\n       [0.88910711],\n       [0.97998703],\n       [0.97553397],\n       [0.88161612],\n       [1.09759966],\n       [1.05956548],\n       [1.01005714],\n       [0.9839512 ],\n       [0.90615507],\n       [0.87535803],\n       [1.08264197],\n       [1.04388833],\n       [0.82812349],\n       [0.94040675],\n       [0.95607608],\n       [0.96663421],\n       [0.99235301],\n       [1.02694774],\n       [0.98903884],\n       [0.89226504],\n       [1.19249096],\n       [1.11355107],\n       [0.9545393 ],\n       [1.15237659],\n       [1.14191461],\n       [0.8359212 ],\n       [0.85211406],\n       [1.03848476],\n       [1.09597861],\n       [0.94059975],\n       [1.036805  ],\n       [0.98529838],\n       [1.03021086],\n       [1.05695783],\n       [0.94658826],\n       [1.12076663],\n       [0.89615998],\n       [1.02990752],\n       [0.99222141],\n       [1.14045641],\n       [0.72715574],\n       [1.03029586],\n       [0.90981875],\n       [0.85601183],\n       [0.91068169],\n       [1.03668822],\n       [1.00556364],\n       [1.01996436],\n       [0.93792949],\n       [0.94672584],\n       [0.923526  ],\n       [0.90352973],\n       [1.28890917],\n       [1.02182617],\n       [0.79206386],\n       [1.15668023],\n       [1.0519807 ],\n       [1.10539368],\n       [1.05042285],\n       [1.11023267],\n       [1.02014104],\n       [0.96922791],\n       [0.89217612],\n       [1.02260451],\n       [1.03940884],\n       [0.8775771 ],\n       [0.9176098 ],\n       [0.92409475],\n       [1.04768895],\n       [0.93647569],\n       [0.94813861],\n       [0.89199369],\n       [0.87028827],\n       [0.99225588],\n       [0.95425621],\n       [1.06984396],\n       [1.00875476],\n       [0.75601709],\n       [0.99022627],\n       [0.92444757],\n       [0.9238476 ],\n       [0.91920221],\n       [1.08043395],\n       [0.81118248],\n       [0.81930578],\n       [1.03586184],\n       [1.06349719],\n       [0.9298171 ],\n       [1.01003849],\n       [0.84307109],\n       [0.9958829 ],\n       [1.0039796 ],\n       [1.02604136],\n       [0.83393572],\n       [0.8507938 ],\n       [0.83454386],\n       [1.02989735],\n       [1.12332218],\n       [1.04397038],\n       [1.05986217],\n       [1.03827628],\n       [0.92618924],\n       [0.7689784 ],\n       [0.92397443],\n       [1.07821487],\n       [1.16314558],\n       [1.00507406],\n       [0.88225003],\n       [0.85395371],\n       [0.95414361],\n       [1.06156825],\n       [0.88053709],\n       [0.99671955],\n       [0.81509875],\n       [0.8132894 ],\n       [1.02724696],\n       [0.90012388],\n       [0.80154278],\n       [1.00876283],\n       [0.94002495],\n       [1.20513817],\n       [0.90070796],\n       [0.98010458],\n       [0.99653393],\n       [0.91368213],\n       [1.02092068]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientDescentLinerRegression(lr=1e-3, seed=1024)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}