{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "((1499, 10000), (1499, 1), (161, 217), (161, 1))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "amazon_X = pd.read_csv(\"data/amazon_X.csv\").to_numpy()\n",
    "amazon_y = pd.read_csv(\"data/amazon_y.csv\").to_numpy()\n",
    "cancer_X = pd.read_csv(\"data/cancer_X.csv\").to_numpy()\n",
    "cancer_y = pd.read_csv(\"data/cancer_y.csv\").to_numpy()\n",
    "amazon_X.shape, amazon_y.shape, cancer_X.shape, cancer_y.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owemshu/opt/anaconda3/envs/deeplearning/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/owemshu/opt/anaconda3/envs/deeplearning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reg = LogisticRegression()\n",
    "reg.fit(amazon_X, amazon_y)\n",
    "reg.score(amazon_X, amazon_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owemshu/opt/anaconda3/envs/deeplearning/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/owemshu/opt/anaconda3/envs/deeplearning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LogisticRegression()\n",
    "reg.fit(cancer_X, cancer_y)\n",
    "reg.score(cancer_X, cancer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class SoftmaxRegression:\n",
    "    def __init__(self):\n",
    "        self.n_samples = None\n",
    "        self.n_features = None\n",
    "        self.n_classes = None\n",
    "        self.weights = None\n",
    "        self.all_loss = list()\n",
    "\n",
    "    def fit(self, x, y, iters=1000, alpha=0.1, lam=0.01):\n",
    "        self.n_samples, self.n_features = x.shape\n",
    "        self.n_classes = y.shape[1]\n",
    "        # self.weights = np.random.rand(self.n_classes, self.n_features)  # 使用随机初始化会造成运算异常\n",
    "        self.weights = np.zeros((self.n_classes, self.n_features))\n",
    "\n",
    "        for i in range(iters):\n",
    "            probs = self._softmax(x)\n",
    "            loss = - (1 / self.n_samples) * np.sum(y * np.nan_to_num(np.log(probs)))\n",
    "            self.all_loss.append(loss)\n",
    "\n",
    "            dw = -(0.5 / self.n_samples) * np.dot((y - probs).T, x) + lam * self.weights\n",
    "            dw[:, 0] -= lam * self.weights[:, 0]\n",
    "            self.weights -= alpha * dw\n",
    "\n",
    "    def predict(self, test_x):\n",
    "        probs = self._softmax(test_x)\n",
    "        return np.argmax(probs, axis=1).reshape((-1, 1))\n",
    "\n",
    "    def score(self, test_x, test_y):\n",
    "        score = 0.0\n",
    "        for i in range(len(test_y)):\n",
    "            if (self.predict([test_x[i]]) == np.argmax(test_y[i])).any():\n",
    "                score += 1\n",
    "        return score / len(test_y)\n",
    "\n",
    "    def _softmax(self, x):\n",
    "        scores = np.dot(x, self.weights.T)\n",
    "        sm = np.exp(scores) / np.sum(np.exp(scores), axis=1, keepdims=True)\n",
    "        sm = np.nan_to_num(sm)\n",
    "        return sm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/wdk87p0d3ml1ysm634x3wlf80000gn/T/ipykernel_18946/1685057548.py:17: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = - (1 / self.n_samples) * np.sum(y * np.nan_to_num(np.log(probs)))\n",
      "/Users/owemshu/opt/anaconda3/envs/deeplearning/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "amazon_y = enc.fit_transform(amazon_y)\n",
    "\n",
    "reg = SoftmaxRegression()\n",
    "reg.fit(amazon_X, amazon_y, alpha=0.01)\n",
    "reg.score(amazon_X, amazon_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(64)\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "cancer_y = enc.fit_transform(cancer_y)\n",
    "\n",
    "reg = SoftmaxRegression()\n",
    "reg.fit(cancer_X, cancer_y)\n",
    "reg.score(cancer_X, cancer_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=200)\n",
    "amazon_X = pca.fit_transform(amazon_X)\n",
    "print(sum(pca.explained_variance_ratio_))\n",
    "\n",
    "normalizer = Normalizer()\n",
    "amazon_X = normalizer.fit_transform(amazon_X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def square_distance(v1, v2):\n",
    "    sum = 0\n",
    "    for i in range(len(v1)):\n",
    "        if v1[i] != v2[i]:\n",
    "            sum += 1\n",
    "    return sum\n",
    "\n",
    "\n",
    "def vote(ys):\n",
    "    vote_dict = {}\n",
    "    for y in ys:\n",
    "        y = y[0]\n",
    "        if y not in vote_dict.keys():\n",
    "            vote_dict[y] = 1\n",
    "        else:\n",
    "            vote_dict[y] += 1\n",
    "    sorted_vote_dict = sorted(vote_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_vote_dict[0][0]  # 将已经记好的数进行一个自大而小的排列(则是一个降序排序），若reverse是false,则是自小而大.(升序排序）\n",
    "\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_pred = []\n",
    "        for i in range(len(x)):\n",
    "            dist_arr = [square_distance(x[i], self.x[j]) for j in range(len(self.x))]\n",
    "            sorted_index = np.argsort(dist_arr)\n",
    "            top_k_index = sorted_index[:self.k]\n",
    "            y_pred.append(vote(ys=self.y[top_k_index]))  # 调用了vote函数，去进行分类\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def score(self, y_true=None, y_pred=None):\n",
    "        if y_true is None and y_pred is None:\n",
    "            y_pred = self.predict(self.x)\n",
    "            y_true = self.y\n",
    "        score = 0.0\n",
    "        for i in range(len(y_true)):\n",
    "            if y_true[i] == y_pred[i]:\n",
    "                score += 1\n",
    "        return score / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "amazon_y = pd.read_csv(\"data/amazon_y.csv\").to_numpy()\n",
    "cancer_y = pd.read_csv(\"data/cancer_y.csv\").to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = KNN()\n",
    "clf.fit(amazon_X, amazon_y)\n",
    "print(clf.score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = KNN()\n",
    "clf.fit(cancer_X, cancer_y)\n",
    "print(clf.score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c41703af27f2ca99b71ea7d43399a85046b4008a212369dfe090ed96ee5033ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
